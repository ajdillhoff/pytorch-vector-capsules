{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Routing Between Capsules\n",
    "\n",
    "This notebook implements and demonstrates the method introduced in this paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How the vector inputs and outputs of a capsule are computed\n",
    "\n",
    "The length of an output vector represents the probability that the entity represented by the capsule is present given the input. To do this, a squashing function is introduced that maps the output between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0456385612487793\n",
      "0.0020627975463867188\n",
      "0.00041675567626953125\n",
      "tensor([[[0.4407, 0.2494],\n",
      "         [0.4033, 0.2699],\n",
      "         [0.1853, 0.4685],\n",
      "         [0.2928, 0.2110]]])\n",
      "tensor([[[0.4407, 0.2494],\n",
      "         [0.4033, 0.2699],\n",
      "         [0.1853, 0.4685],\n",
      "         [0.2928, 0.2110]]])\n",
      "tensor([[[0.4407, 0.2494],\n",
      "         [0.4033, 0.2699],\n",
      "         [0.1853, 0.4685],\n",
      "         [0.2928, 0.2110]]])\n"
     ]
    }
   ],
   "source": [
    "def squash1(x):\n",
    "    \"\"\"https://github.com/higgsfield/Capsule-Network-Tutorial/blob/master/Capsule%20Network.ipynb\"\"\"\n",
    "    squared_norm = (x ** 2).sum(-1, keepdim=True)\n",
    "    return squared_norm * x / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
    "\n",
    "def squash2(x):\n",
    "    \"\"\"My interpretation.\"\"\"\n",
    "    x_norm = x.norm(dim=-1, keepdim=True) ** 2\n",
    "    return (x_norm / (1 + x_norm)) * (x / torch.sqrt(x_norm))\n",
    "\n",
    "def squash3(x, dim=-1):\n",
    "    \"\"\"https://github.com/gram-ai/capsule-networks/blob/master/capsule_network.py\"\"\"\n",
    "    squared_norm = (x ** 2).sum(dim=dim, keepdim=True)\n",
    "    scale = squared_norm / (1 + squared_norm)\n",
    "    return scale * x / torch.sqrt(squared_norm)\n",
    "\n",
    "x = torch.rand(1, 4, 2)\n",
    "t1 = time.time()\n",
    "s1 = squash1(x)\n",
    "print(time.time() - t1)\n",
    "t1 = time.time()\n",
    "s2 = squash2(x)\n",
    "print(time.time() - t1)\n",
    "t1 = time.time()\n",
    "s3 = squash3(x)\n",
    "print(time.time() - t1)\n",
    "print(s1)\n",
    "print(s2)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is `s` and where does it come from?\n",
    "\n",
    "`s_j` is the input to capsule *j*. It comes from a weighted sum of prediction vectors `u_hat` and coupling coefficients (more on that later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9763, 0.5313, 0.7494],\n",
      "        [1.3963, 0.5850, 1.1037]])\n",
      "tensor([[0.9763, 0.5313, 0.7494],\n",
      "        [1.3963, 0.5850, 1.1037]])\n",
      "tensor([[0.4679, 0.2546, 0.3592],\n",
      "        [0.5800, 0.2430, 0.4585]])\n"
     ]
    }
   ],
   "source": [
    "N = 4  # number of capsules in layer 0\n",
    "M = 2  # number of capsules in layer 1\n",
    "D = 3  # dimension of capsule in layer 0\n",
    "c = torch.rand(M, N)\n",
    "u_hat = torch.rand(N, D)\n",
    "\n",
    "s = torch.empty(M, D)\n",
    "\n",
    "# Calculating s_j\n",
    "for j in range(M):\n",
    "    for i in range(N):\n",
    "        s[j] += c[j,i] * u_hat[i]\n",
    "print(s)\n",
    "print(c @ u_hat)\n",
    "print(squash2(c @ u_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routing\n",
    "\n",
    "Measure the agreement between the current output of each capsule in the higher layer with each prediction from the lower capsules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5693, 0.3967, 0.1622],\n",
      "        [0.1070, 0.1079, 0.8489],\n",
      "        [0.0482, 0.4059, 0.0409],\n",
      "        [0.8526, 0.1019, 0.7829]])\n",
      "tensor([[0.1808, 0.1161, 0.2104],\n",
      "        [0.1808, 0.1161, 0.2104]])\n"
     ]
    }
   ],
   "source": [
    "def routing(u_hat, r, l):\n",
    "    \"\"\"Computes the output vector for the capsule while updating the coupling\n",
    "    coefficients.\n",
    "    \n",
    "    Args:\n",
    "        u_hat (D): Prediction from lower level capsule.\n",
    "        r (int): Number of iterations.\n",
    "        l (int): Current layer.\n",
    "    Returns:\n",
    "        v (D): Output vector.\n",
    "    \"\"\"\n",
    "    b = torch.zeros(M, N)\n",
    "    \n",
    "    for i in range(r):\n",
    "        # for all capsule i in layer l\n",
    "        c = F.softmax(b, dim=-1)\n",
    "        \n",
    "        # for all capsule j in layer (l+1)\n",
    "        s = c @ u_hat\n",
    "        print(u_hat)\n",
    "        \n",
    "        # for all capsule j in layer (l+1)\n",
    "        v = squash2(s)\n",
    "        \n",
    "        if i < r - 1:\n",
    "            b += v @ u_hat.transpose(0, 1)\n",
    "            \n",
    "        return v\n",
    "        \n",
    "v = routing(u_hat, 3, 0)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Margin loss for digit existence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.3688)\n"
     ]
    }
   ],
   "source": [
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lam = 0.5\n",
    "labels = torch.empty(4, 10, dtype=torch.float32).random_(2)\n",
    "\n",
    "x = torch.rand(4, 10, 16)\n",
    "v_c = x.norm(p=2, dim=-1, keepdim=True)\n",
    "left = F.relu(m_plus - v_c).view(4, -1)\n",
    "right = F.relu(v_c - m_minus).view(4, -1)\n",
    "loss = labels * left + lam * (1.0 - labels) * right\n",
    "loss = loss.sum(dim=1).mean()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primary Capsule\n",
    "\n",
    "Primary capsules consist of a convolutional layer with 32 channels of convolutional 8D capsules. This means that each primary capsule contains 8 conv units with a 9x9 kernel and stride 2. `PrimaryCapsules` has (32x6x6) capsule outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCapsule(nn.Module):\n",
    "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32, kernel_size=9):\n",
    "        super(PrimaryCapsule, self).__init__()\n",
    "        # Initialize the convolutional capsules\n",
    "        self.capsules = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=2, padding=0) for _ in range(num_capsules)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Prediction for each capsule\n",
    "        u = [capsule(x) for capsule in self.capsules]\n",
    "        u = torch.stack(u, dim=1)\n",
    "        u = u.view(x.size(0), 32 * 6 * 6, -1)\n",
    "        return squash2(u)\n",
    "        \n",
    "cap = PrimaryCapsule()\n",
    "conv1 = nn.Conv2d(1, 256, kernel_size=9, stride=1)\n",
    "x = torch.rand(4, 1, 28, 28)\n",
    "x = conv1.forward(x)\n",
    "x = cap(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Capsule\n",
    "Digit capsules implement the routing mechanism to determine the part-whole relationships based on the predictions of the primary capsules.\n",
    "\n",
    "  $W_{ij}$ - Learned weights which are multiplied with the capsule output $u_i$ to produce the prediction vectors $\\hat{u}_{j|i}$.\n",
    "  \n",
    "  $b_{ij}$ - Log prior probabilities that capsule $i$ should be coupled to capsule $j$.\n",
    "  \n",
    "  $c_{ij}$ - Coupling coefficients between capsule $i$ and all capsules in the higher layer. These sum to 1 for each capsule in the lower layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitCap(nn.Module):\n",
    "    def __init__(self, num_capsules=10, in_size=32 * 6 * 6, in_channels=8, out_channels=16,\n",
    "                num_iterations=3):\n",
    "        super(DigitCap, self).__init__()\n",
    "        self.num_iterations = 3\n",
    "        self.W = nn.Parameter(torch.randn(num_capsules, in_size, in_channels, out_channels))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        u_ji = x[:, None, :, None, :] @ self.W[None, :, :, :, :]\n",
    "        u_ji = u_ji.squeeze(3)\n",
    "        b_ij = torch.zeros(u_ji.shape, device=x.device)\n",
    "        \n",
    "        for i in range(self.num_iterations):\n",
    "            c_ij = F.softmax(b_ij, dim=2)\n",
    "            v_j = squash2((c_ij * u_ji).sum(dim=2, keepdim=True))\n",
    "            \n",
    "            if i < self.num_iterations - 1:\n",
    "                a_ij = (u_ji * v_j).sum(dim=-1, keepdim=True)\n",
    "                b_ij = b_ij + a_ij\n",
    "        \n",
    "        return v_j.squeeze(2)\n",
    "    \n",
    "dcap = DigitCap()\n",
    "v = dcap(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction as a regularization method\n",
    "\n",
    "A decoder is proposed which would attempt to reconstruct the digit image using the activation of the corresponding digit vector in `DigitCap`. This is done by masking out all activity vectors except for the one corresponding to the correct label. This is then transformed through 3 fully connected layers. The output is a 784 dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels=16 * 10):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_channels, 512)\n",
    "        self.fc2 = nn.Linear(512, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 784)\n",
    "        \n",
    "    def forward(self, x, labels):\n",
    "        mask = torch.sparse.torch.eye(10)\n",
    "#         mask = mask.index_select(dim=0, index=labels.squeeze(1))\n",
    "        x = x * mask[labels.squeeze(1), :, None]\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x.view(-1, 1, 28, 28)\n",
    "        \n",
    "x = torch.randn(2, 10, 16)\n",
    "labels = torch.randint(0, 9, (2, 1))\n",
    "dec = Decoder()\n",
    "img = dec(x, labels)\n",
    "print(F.mse_loss(img, img))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch1.0)",
   "language": "python",
   "name": "pytorch1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
